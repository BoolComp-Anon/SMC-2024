{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "32BitsModels.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TTb0lA-mcwLl",
        "VQ7IE0uYl1Ow",
        "geh3HVEcbGOK"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AWvjndluGeV"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from joblib import dump, load"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYRCk8RkNrks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04383f9e-fbdd-48ef-c2ee-2f241a4cd4cc"
      },
      "source": [
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0TibRvfTjyv"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/32bitdata/bitsDataset.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PLHe-OYT60L"
      },
      "source": [
        "bitsCols = []\n",
        "for i in range(31,-1,-1):\n",
        "  bitsCols.append('Bit {}'.format(i))\n",
        "X = df.loc[:, bitsCols]\n",
        "Y = df.loc[:, 'Class']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHAGYuzsTzwE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "#15% train 85% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.85, random_state=0)\n",
        "\n",
        "#We initialize data structures and the regularization parameter.\n",
        "regul_param = 10.0 ** -2\n",
        "\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "clasificadores = []\n",
        "clf_nom = []\n",
        "clf_top = []\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTb0lA-mcwLl"
      },
      "source": [
        "# **In case you want to train the models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUmwER3owRXh"
      },
      "source": [
        "## **Initial 200 neuron models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZONF9nYj0Pb9"
      },
      "source": [
        "clf200=MLPClassifier(hidden_layer_sizes=(200, ), activation='relu', solver='adam', alpha=regul_param, batch_size='auto',\n",
        "                   learning_rate='constant', learning_rate_init=0.001, max_iter=200,verbose= True, random_state = 333).fit(X_train, y_train.ravel())\n",
        "clear_output()\n",
        "clasificadores.append(clf200)\n",
        "clf_nom.append('clf200')\n",
        "clf_top.append('200')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93oIfdvY0TLu"
      },
      "source": [
        "clf155=MLPClassifier(hidden_layer_sizes=(100,50,50, ), activation='relu', solver='adam', alpha=regul_param, batch_size='auto',\n",
        "                   learning_rate='constant', learning_rate_init=0.001, max_iter=200,verbose= True, random_state = 333).fit(X_train, y_train.ravel())\n",
        "clear_output()\n",
        "clasificadores.append(clf155)\n",
        "clf_nom.append('clf155')\n",
        "clf_top.append('100,50,50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKnTiHEz0Xpb"
      },
      "source": [
        "## **Different 100 neuron topologies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0AkCcf41OLq"
      },
      "source": [
        "clf100=MLPClassifier(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=regul_param, batch_size='auto', \n",
        "                    learning_rate='constant', learning_rate_init=0.001, max_iter=200,verbose= True, random_state = 333).fit(X_train, y_train.ravel())\n",
        "clear_output()\n",
        "clasificadores.append(clf100)\n",
        "clf_nom.append('clf100')\n",
        "clf_top.append('100')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS7I80OB1fuv"
      },
      "source": [
        "clf80=MLPClassifier(hidden_layer_sizes=(80,15,5, ), activation='relu', solver='adam', alpha=regul_param, batch_size='auto', \n",
        "                    learning_rate='constant', learning_rate_init=0.001, max_iter=200,verbose= True, random_state = 333).fit(X_train, y_train.ravel())\n",
        "clear_output()\n",
        "clasificadores.append(clf80)\n",
        "clf_nom.append('clf80')\n",
        "clf_top.append('80,15,5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ORjU2tj1gHx"
      },
      "source": [
        "clf70=MLPClassifier(hidden_layer_sizes=(70,25,5, ), activation='relu', solver='adam', alpha=regul_param, batch_size='auto',\n",
        "                    learning_rate='constant', learning_rate_init=0.001, max_iter=200,verbose= True, random_state = 333).fit(X_train, y_train.ravel())\n",
        "clear_output()\n",
        "clasificadores.append(clf70)\n",
        "clf_nom.append('clf70')\n",
        "clf_top.append('70,25,5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Joqvpr6E1gd-"
      },
      "source": [
        "clf5050=MLPClassifier(hidden_layer_sizes=(50,50, ), activation='relu', solver='adam', alpha=regul_param, batch_size='auto',\n",
        "                      learning_rate='constant', learning_rate_init=0.001, max_iter=200,verbose= True, random_state = 333).fit(X_train, y_train.ravel())\n",
        "clear_output()\n",
        "clasificadores.append(clf5050)\n",
        "clf_nom.append('clf5050')\n",
        "clf_top.append('50,50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXSgaEKp1mCc"
      },
      "source": [
        "clf5025=MLPClassifier(hidden_layer_sizes=(50,25,25, ), activation='relu', solver='adam', alpha=regul_param, batch_size='auto',\n",
        "                      learning_rate='constant', learning_rate_init=0.001, max_iter=200,verbose= True, random_state = 333).fit(X_train, y_train.ravel())\n",
        "clear_output()\n",
        "clasificadores.append(clf5025)\n",
        "clf_nom.append('clf5025')\n",
        "clf_top.append('50,25,25')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7N5G6VTEhk4"
      },
      "source": [
        "clf5030=MLPClassifier(hidden_layer_sizes=(50,30,10,10, ), activation='relu', solver='adam', alpha=regul_param, batch_size='auto',\n",
        "                      learning_rate='constant', learning_rate_init=0.001, max_iter=200,verbose= True, random_state = 333).fit(X_train, y_train.ravel())\n",
        "clear_output()\n",
        "clasificadores.append(clf5030)\n",
        "clf_nom.append('clf5030')\n",
        "clf_top.append('50,30,10,10')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPPYwP8zaV6L"
      },
      "source": [
        "## **Refined 200 neuron topology**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miIcbUFLaKoW"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "regul_param = 10.0 ** -2\n",
        "\n",
        "MLP=MLPClassifier(hidden_layer_sizes=(160,25,10,5, ), activation='relu', solver='adam', alpha=regul_param, batch_size='auto', \n",
        "             learning_rate='constant', learning_rate_init=0.001, max_iter=500,verbose= True, random_state = 333).fit(X_train, y_train.ravel())\n",
        "clear_output()\n",
        "clasificadores.append(MLP)\n",
        "clf_nom.append('MLP')\n",
        "clf_top.append('160,25,10,5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpPc4YmxevMI"
      },
      "source": [
        "## **To save weights and biases**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsmEoeGDe_rl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84c82f0-49a2-4bdb-c6cd-e7ff606813e7"
      },
      "source": [
        "#We check that we have the trained models\n",
        "print(len(clasificadores))\n",
        "print(len(clf_nom), ' ', clf_nom)\n",
        "print(len(clf_top), ' ', clf_top)\n",
        "print(len(train_scores), ' ', train_scores)\n",
        "print(len(test_scores), ' ', test_scores)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "9   ['clf200', 'clf155', 'clf100', 'clf80', 'clf70', 'clf5050', 'clf5025', 'clf5030', 'MLP']\n",
            "9   ['200', '100,50,50', '100', '80,15,5', '70,25,5', '50,50', '50,25,25', '50,30,10,10', '160,25,10,5']\n",
            "9   [0.9833149081450171, 0.9888782311819216, 0.9763615672248415, 0.9830840513737603, 0.9829279791903756, 0.9768216550154446, 0.9761063241749309, 0.9787042757275239, 0.9895626727361405]\n",
            "9   [0.9817246428702582, 0.98507818524843, 0.9754384364327421, 0.9813416349932063, 0.9810223183136866, 0.9754688475450773, 0.974817590705446, 0.9772510534868348, 0.9864550053248136]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7gnio9JfvS_"
      },
      "source": [
        "#We save the data to .joblib files\n",
        "for i in range(len(clasificadores)):\n",
        "  filename= clf_nom[i] + '.joblib'\n",
        "  dump(clasificadores[i],filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CziD0N7PeIF5"
      },
      "source": [
        "# **In case you want to import weights and biases from pre-trained models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FNfbbcJeRAr"
      },
      "source": [
        "clf200= load(\"/content/drive/MyDrive/32bitdata/clf200.joblib\")\n",
        "clasificadores.append(clf200)\n",
        "clf_nom.append('clf200')\n",
        "clf_top.append('200')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuJ_lx_7joZn"
      },
      "source": [
        "clf155= load(\"/content/drive/MyDrive/32bitdata/clf155.joblib\")\n",
        "clasificadores.append(clf155)\n",
        "clf_nom.append('clf155')\n",
        "clf_top.append('100,50,50')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzP-6n9Tjolg"
      },
      "source": [
        "clf100= load(\"/content/drive/MyDrive/32bitdata/clf100.joblib\")\n",
        "clasificadores.append(clf100)\n",
        "clf_nom.append('clf100')\n",
        "clf_top.append('100')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fExudE35jotc"
      },
      "source": [
        "clf80= load(\"/content/drive/MyDrive/32bitdata/clf80.joblib\")\n",
        "clasificadores.append(clf80)\n",
        "clf_nom.append('clf80')\n",
        "clf_top.append('80,15,5')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAPYFaP7joxk"
      },
      "source": [
        "clf70= load(\"/content/drive/MyDrive/32bitdata/clf70.joblib\")\n",
        "clasificadores.append(clf70)\n",
        "clf_nom.append('clf70')\n",
        "clf_top.append('70,25,5')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVKEqCM7jo1R"
      },
      "source": [
        "clf5050= load(\"/content/drive/MyDrive/32bitdata/clf5050.joblib\")\n",
        "clasificadores.append(clf5050)\n",
        "clf_nom.append('clf5050')\n",
        "clf_top.append('50,50')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r-F-n2sjo_b"
      },
      "source": [
        "clf5025= load(\"/content/drive/MyDrive/32bitdata/clf5025.joblib\")\n",
        "clasificadores.append(clf5025)\n",
        "clf_nom.append('clf5025')\n",
        "clf_top.append('50,25,25')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MTkjI7XjpK-"
      },
      "source": [
        "clf5030= load(\"/content/drive/MyDrive/32bitdata/clf5030.joblib\")\n",
        "clasificadores.append(clf5030)\n",
        "clf_nom.append('clf5030')\n",
        "clf_top.append('50,30,10,10')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0PXAnL5kzEk"
      },
      "source": [
        "MLP= load(\"/content/drive/MyDrive/32bitdata/MLP.joblib\")\n",
        "clasificadores.append(MLP)\n",
        "clf_nom.append('MLP')\n",
        "clf_top.append('160,25,10,5')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NES7TWRrlLDM"
      },
      "source": [
        "# **Computing train and test accuracies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqCPZgtu17Z6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dbf5534-ceb5-4b85-a7bb-a5c867f535b2"
      },
      "source": [
        "for i in range(len(clasificadores)):\n",
        "  print('Topology ',clf_top[i],':')\n",
        "  y_train_pred= clasificadores[i].predict(X_train)\n",
        "  y_test_pred = clasificadores[i].predict(X_test)\n",
        "  f_train = f1_score(y_train, y_train_pred, average='micro')\n",
        "  print(' Train: ', f_train)\n",
        "  f_test = f1_score(y_test, y_test_pred, average='micro')\n",
        "  print(' Test: ', f_test)\n",
        "  train_scores.append(f_train)\n",
        "  test_scores.append(f_test)\n",
        "  print('')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topology  200 :\n",
            " Train:  0.9833149081450171\n",
            " Test:  0.9817246428702582\n",
            "\n",
            "Topology  100,50,50 :\n",
            " Train:  0.9888782311819216\n",
            " Test:  0.98507818524843\n",
            "\n",
            "Topology  100 :\n",
            " Train:  0.9763615672248415\n",
            " Test:  0.9754384364327421\n",
            "\n",
            "Topology  80,15,5 :\n",
            " Train:  0.9830840513737603\n",
            " Test:  0.9813416349932063\n",
            "\n",
            "Topology  70,25,5 :\n",
            " Train:  0.9829279791903756\n",
            " Test:  0.9810223183136866\n",
            "\n",
            "Topology  50,50 :\n",
            " Train:  0.9768216550154446\n",
            " Test:  0.9754688475450773\n",
            "\n",
            "Topology  50,25,25 :\n",
            " Train:  0.9761063241749309\n",
            " Test:  0.974817590705446\n",
            "\n",
            "Topology  50,30,10,10 :\n",
            " Train:  0.9787042757275239\n",
            " Test:  0.9772510534868348\n",
            "\n",
            "Topology  160,25,10,5 :\n",
            " Train:  0.9895626727361405\n",
            " Test:  0.9864550053248136\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaK98kqBWtw6",
        "outputId": "140ea2a3-b5df-4406-fd81-3e9c765dc122"
      },
      "source": [
        "#We check that we have the trained models\n",
        "print(len(clasificadores))\n",
        "print(len(clf_nom), ' ', clf_nom)\n",
        "print(len(clf_top), ' ', clf_top)\n",
        "print(len(train_scores), ' ', train_scores)\n",
        "print(len(test_scores), ' ', test_scores)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "9   ['clf200', 'clf155', 'clf100', 'clf80', 'clf70', 'clf5050', 'clf5025', 'clf5030', 'MLP']\n",
            "9   ['200', '100,50,50', '100', '80,15,5', '70,25,5', '50,50', '50,25,25', '50,30,10,10', '160,25,10,5']\n",
            "9   [0.9833149081450171, 0.9888782311819216, 0.9763615672248415, 0.9830840513737603, 0.9829279791903756, 0.9768216550154446, 0.9761063241749309, 0.9787042757275239, 0.9895626727361405]\n",
            "9   [0.9817246428702582, 0.98507818524843, 0.9754384364327421, 0.9813416349932063, 0.9810223183136866, 0.9754688475450773, 0.974817590705446, 0.9772510534868348, 0.9864550053248136]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "hl_QuPmFWlB6",
        "outputId": "01c911fe-136b-4aef-dd3d-6c5778216d0a"
      },
      "source": [
        "#pltdf = pd.DataFrame({'Train': train_scores,'Test': test_scores}, index=clf_top)\n",
        "pltdf = pd.DataFrame({'Train': train_scores,'Test': test_scores}, index=clf_nom)\n",
        "\n",
        "sup = 1.005*max(max(train_scores),max(test_scores))\n",
        "inf = 0.995*min(min(train_scores),min(test_scores))\n",
        "ax = pltdf.plot.bar(rot=0,figsize=(16,9),ylim=[inf,sup])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ7IE0uYl1Ow"
      },
      "source": [
        "## **To obtain more deatails of an specific classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rglOV2ElatXZ",
        "outputId": "3634bb10-9e05-4bd9-dbfc-c46295c49912"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "classifier = MLP\n",
        "y_test_pred = classifier.predict(X_test)\n",
        "print(classification_report(y_test, y_test_pred, digits= 4))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "Complementario     0.9861    0.9868    0.9865   1742986\n",
            "       Dataset     0.9868    0.9861    0.9864   1742582\n",
            "\n",
            "      accuracy                         0.9865   3485568\n",
            "     macro avg     0.9865    0.9865    0.9865   3485568\n",
            "  weighted avg     0.9865    0.9865    0.9865   3485568\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PIpao_ua62h"
      },
      "source": [
        "# Funtion imported from\n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = unique_labels(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='Actual Label',\n",
        "           xlabel='Predicted Label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.4f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    if normalize:\n",
        "        title+= ' (normalized)'\n",
        "    plt.savefig(title+'.pdf')\n",
        "    return ax\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "ZTAQch3ba9yq",
        "outputId": "24d0c702-b4a0-40a3-db1b-dba4d1f350dd"
      },
      "source": [
        "plot_confusion_matrix(y_test, y_test_pred, normalize = False, title='Model')\n",
        "plot_confusion_matrix(y_test, y_test_pred, normalize = True, title='Model')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix\n",
            "[[1719958   23028]\n",
            " [  24184 1718398]]\n",
            "Normalized confusion matrix\n",
            "[[0.98678819 0.01321181]\n",
            " [0.01387826 0.98612174]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3f7805a7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geh3HVEcbGOK"
      },
      "source": [
        "# **r-Weight computation of the 100 neuron, single-layer MLP**\n",
        "\n",
        "To compute first layer r-weights in the single-layer MLP we compute each neuron's weight matrix by the neuron's weight for the output neuron's lineal combination.\n",
        "\n",
        "For a rough first visualization, we arrange the r-weights as a 8x4 matrix in descending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sqT-_KNW0zvi",
        "outputId": "2621ad54-4f56-4cd1-9b95-edec7ed905c5"
      },
      "source": [
        "np.set_printoptions(precision=2,suppress=True)\n",
        "for i in range(100):\n",
        "  v = clf100.coefs_[0].T[i] * clf100.coefs_[1][i]\n",
        "  v = v.reshape(4,8)\n",
        "  print(v)\n",
        "  print()\n",
        "\n",
        "clf100.coefs_[0].shape\n",
        "\n",
        "'''   Input bit leyend\n",
        "      ____________________________________________________________\n",
        "      |              1             |||              0            |<--b2\n",
        "      |-------------++-------------+++------+------++------+-----|\n",
        "      |      1      ||      0      |||      1      ||      0     |<--b1\n",
        "______|-------------++-------------+++------+------++------+-----|\n",
        "|b4|b5|   1  |   0  ||  1   |   0  |||   1  |   0  ||  1   |  0  |<--b0\n",
        "|--+--+------+------++-------------+++-------------++------+-----|\n",
        "|1 |  |-0.04 | 0.05 || 0.04 |-0.03 |||-1.16 | 1.17 || 1.15 |-1.14|\n",
        "|--+ 1+------+------++-------------+++-------------++------+-----|\n",
        "|0 |  |-0.09 | 0.07 || 0.07 |-0.1  ||| 1.03 |-0.99 ||-1.04 | 1.01|\n",
        "|--+--+------+------++-------------+++-------------++------+-----|\n",
        "|--+--+------+------++-------------+++-------------++------+-----|\n",
        "|1 |  |-0.   | 0.04 || 0.   |-0.03 ||| 0.   | 0.03 || 0.03 |-0.01|\n",
        "|--+ 0+------+------++-------------+++-------------++------+-----|\n",
        "|0 |  |-0.01 |-0.   || 0.02 | 0.02 ||| 0.   |-0.01 ||-0.01 |-0.03|\n",
        "|----------------------------------------------------------------|\n",
        "\n",
        "Output\n",
        "[[-0.04  0.05  0.04 -0.03 -1.16  1.17  1.15 -1.14]\n",
        " [-0.09  0.07  0.07 -0.1   1.03 -0.99 -1.04  1.01]\n",
        " [-0.    0.04  0.   -0.03  0.    0.03  0.03 -0.01]\n",
        " [-0.01 -0.    0.02  0.02  0.   -0.01 -0.01 -0.03]]\n",
        "\n",
        " '''\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.04  0.05  0.04 -0.03 -1.16  1.17  1.15 -1.14]\n",
            " [-0.09  0.07  0.07 -0.1   1.03 -0.99 -1.04  1.01]\n",
            " [-0.    0.04  0.   -0.03  0.    0.03  0.03 -0.01]\n",
            " [-0.01 -0.    0.02  0.02  0.   -0.01 -0.01 -0.03]]\n",
            "\n",
            "[[ 0.99  1.   -1.01 -1.   -1.04 -1.    1.02  1.03]\n",
            " [-1.28 -1.26  1.29  1.3   1.31  1.28 -1.32 -1.32]\n",
            " [-0.02  0.   -0.04 -0.03  0.01 -0.01  0.03  0.  ]\n",
            " [ 0.01  0.02  0.01  0.02  0.01 -0.   -0.01  0.  ]]\n",
            "\n",
            "[[-0.99  0.77  0.72 -1.03  0.4  -0.76 -0.71  0.73]\n",
            " [ 0.78 -1.01 -1.22  1.19 -0.91  0.62  0.95 -1.35]\n",
            " [-0.09 -0.14 -0.13 -0.07 -0.15 -0.14 -0.49  0.33]\n",
            " [-0.03 -0.15 -0.05 -0.4  -0.06  0.34  0.12 -0.58]]\n",
            "\n",
            "[[-0.85 -0.02  0.85 -0.01  0.86  0.01 -0.88 -0.  ]\n",
            " [ 0.89 -0.   -0.86 -0.01 -0.85 -0.    0.86  0.01]\n",
            " [ 1.06 -0.01 -1.04 -0.04 -1.05  0.03  1.1   0.01]\n",
            " [-1.05  0.01  1.05 -0.01  1.06  0.02 -1.04  0.03]]\n",
            "\n",
            "[[-0.1   0.92 -0.12  0.97  0.14 -0.99  0.12 -0.98]\n",
            " [-0.13  0.9  -0.11  0.95  0.11 -0.97  0.12 -0.93]\n",
            " [ 0.12 -1.19  0.08 -1.19 -0.09  1.2  -0.1   1.21]\n",
            " [ 0.08 -1.15  0.1  -1.17 -0.07  1.19 -0.06  1.16]]\n",
            "\n",
            "[[-0.1  -0.11 -0.14 -0.11  0.04 -0.17  0.03 -0.19]\n",
            " [-0.12  0.23 -0.07 -0.4   0.01  1.07 -0.13  0.71]\n",
            " [-0.11  0.04 -0.06 -0.06 -0.02  0.08  0.05 -0.1 ]\n",
            " [ 0.12  0.77 -0.13  0.5   0.05 -2.93 -0.15  1.31]]\n",
            "\n",
            "[[ 0.03  0.03 -0.05  0.03  0.03 -0.01 -0.02 -0.02]\n",
            " [ 0.01  0.07  0.01  0.03 -0.    0.07  0.04  0.03]\n",
            " [ 0.02  0.05  0.04  0.02  0.01 -0.02  0.   -0.01]\n",
            " [ 1.75  1.73 -1.61 -1.6  -0.58 -0.58  0.48  0.5 ]]\n",
            "\n",
            "[[ 0.19  0.02 -0.07 -0.12 -0.03  0.02  0.16  0.1 ]\n",
            " [-0.02 -0.02  0.09  0.02 -0.03 -0.08  0.11 -0.28]\n",
            " [-0.11  0.18  0.29 -0.12  0.02 -0.03 -1.5   1.31]\n",
            " [ 0.11 -0.12 -0.12 -0.01 -0.13  0.25  1.47  1.06]]\n",
            "\n",
            "[[ 0.03 -0.53  0.44  0.14 -0.02  0.   -0.26 -0.06]\n",
            " [ 0.13  0.59 -0.43 -0.18 -0.12 -0.1   0.21 -0.14]\n",
            " [-0.6  -0.01 -0.01  0.14 -0.3   0.2   0.51  0.41]\n",
            " [ 0.3  -0.07 -0.27 -0.12  0.02 -0.06  0.12 -0.35]]\n",
            "\n",
            "[[-0.02 -0.01 -0.04  0.03  1.07 -1.09 -0.82  0.84]\n",
            " [-0.01 -0.02 -0.03  0.02  1.08 -1.07 -0.82  0.81]\n",
            " [-0.01  0.   -0.01  0.01  1.08 -1.07 -0.81  0.82]\n",
            " [ 0.    0.02 -0.   -0.01  1.07 -1.05 -0.81  0.79]]\n",
            "\n",
            "[[ 0.66 -0.66  0.67 -0.69 -0.76  0.76 -0.76  0.77]\n",
            " [-0.64  0.64 -0.65  0.65  0.75 -0.73  0.75 -0.76]\n",
            " [ 0.    0.    0.01  0.02  0.    0.01  0.02  0.02]\n",
            " [ 0.01 -0.02 -0.02  0.    0.01 -0.02  0.01 -0.01]]\n",
            "\n",
            "[[ 1.31  0.03  1.32  0.01 -1.36  0.02 -1.33 -0.01]\n",
            " [-0.18 -0.   -0.09  0.02  0.08 -0.03  0.14 -0.03]\n",
            " [-1.85  0.08 -1.84  0.12  1.88 -0.11  1.85 -0.1 ]\n",
            " [-0.04 -0.01 -0.03 -0.01  0.09 -0.    0.08 -0.03]]\n",
            "\n",
            "[[ 0.01 -0.45 -0.21  0.27  0.44  0.28 -0.15 -0.08]\n",
            " [-0.25  0.14  0.34 -0.36 -0.33  0.17 -0.07 -0.16]\n",
            " [ 0.33  0.78  0.04 -0.01 -0.74  0.77 -0.09 -0.25]\n",
            " [ 0.18 -0.56 -0.12 -0.07  0.06  0.2   0.07  0.4 ]]\n",
            "\n",
            "[[ 0.66  0.67 -0.74 -0.74  0.67  0.69 -0.74 -0.74]\n",
            " [ 0.67  0.67 -0.73 -0.75  0.7   0.69 -0.74 -0.76]\n",
            " [-0.67 -0.68  0.74  0.73 -0.69 -0.71  0.73  0.74]\n",
            " [-0.67 -0.67  0.77  0.77 -0.69 -0.69  0.77  0.74]]\n",
            "\n",
            "[[ 0.  0.  0.  0.  0. -0. -0.  0.]\n",
            " [ 0. -0.  0. -0.  0.  0. -0. -0.]\n",
            " [ 0.  0.  0.  0.  0. -0. -0.  0.]\n",
            " [ 0. -0.  0.  0.  0. -0.  0. -0.]]\n",
            "\n",
            "[[-0.01  0.07  0.01  0.04  0.06 -0.67  0.05 -0.31]\n",
            " [-0.13  0.21 -0.02  0.27  0.18 -0.12  0.19  0.7 ]\n",
            " [-0.14 -0.24 -0.09  0.21  0.15  2.72 -0.02 -1.22]\n",
            " [ 0.16 -0.02  0.04  0.1  -0.12 -2.    0.26 -0.82]]\n",
            "\n",
            "[[-1.16  0.52  0.86  0.38  0.28  0.03 -0.16  0.26]\n",
            " [ 0.29  0.16 -0.16 -0.36 -0.29 -0.32 -0.17  0.12]\n",
            " [-0.29 -0.15 -0.29 -0.08 -0.05 -0.08  0.18 -0.  ]\n",
            " [ 0.36 -0.08 -0.26 -0.02  0.43 -0.12 -0.32  0.34]]\n",
            "\n",
            "[[-1.29  1.28  1.22 -1.19  1.25 -1.22 -1.21  1.1 ]\n",
            " [-0.13  0.07  0.09 -0.    0.    0.02  0.03  0.05]\n",
            " [-0.11  0.08  0.1   0.    0.03 -0.07 -0.01 -0.08]\n",
            " [-0.05  0.04  0.02  0.01 -0.07  0.05 -0.03  0.01]]\n",
            "\n",
            "[[ 0.05 -0.07  0.03 -1.64 -0.05  0.06 -0.06  1.69]\n",
            " [-0.03  0.03  0.06  1.61 -0.12  0.13  0.04 -1.63]\n",
            " [-0.03 -0.   -0.04  1.66  0.08 -0.06  0.08 -1.61]\n",
            " [ 0.03  0.01 -0.   -1.57  0.04  0.   -0.03  1.61]]\n",
            "\n",
            "[[ 0.11  0.23  0.06 -0.15 -0.28  0.01 -0.16  0.19]\n",
            " [-0.2   0.09 -0.02  0.1   1.75 -1.08 -0.89 -0.5 ]\n",
            " [-0.1   0.05  0.02  0.02  0.25 -0.03  0.08  0.08]\n",
            " [ 0.11  0.08 -0.06  0.14 -0.47 -0.26 -0.23  0.35]]\n",
            "\n",
            "[[-0.1  -0.08 -0.    0.07  0.24  0.04  0.08  0.01]\n",
            " [-0.12 -0.04  0.21 -0.09  0.1   0.16  0.25  0.06]\n",
            " [-0.09  0.32  0.11  0.22 -0.   -0.05  0.12 -0.01]\n",
            " [ 0.08 -0.04 -0.03  0.14  0.02  0.18  0.01 -0.06]]\n",
            "\n",
            "[[-0.08 -0.01 -0.13 -0.08 -0.05  0.08  0.01  0.04]\n",
            " [ 1.46 -1.42  0.02  0.08 -1.52  1.57  0.    0.01]\n",
            " [ 0.02 -0.   -0.04 -0.05  0.08  0.02  0.04  0.04]\n",
            " [-1.71  1.78 -0.05  0.12  1.77 -1.74  0.12  0.05]]\n",
            "\n",
            "[[-1.07  1.21  1.16 -1.24 -1.08  1.23  1.17 -1.22]\n",
            " [-0.04  0.09  0.02 -0.04 -0.01  0.07  0.04 -0.01]\n",
            " [ 1.05 -1.25 -1.15  1.24  1.08 -1.26 -1.18  1.25]\n",
            " [-0.06 -0.05 -0.    0.06  0.02 -0.06  0.07  0.04]]\n",
            "\n",
            "[[ 0.59 -0.02 -0.12 -0.96 -0.   -1.11 -0.83  1.23]\n",
            " [-0.09 -0.68 -0.85  0.87 -0.95  0.8   1.36 -2.67]\n",
            " [-0.33 -0.9  -0.92  1.35 -0.74  1.07  1.09 -2.6 ]\n",
            " [-0.93  0.88  1.32 -2.17  1.2  -2.03 -2.82  5.36]]\n",
            "\n",
            "[[-0.11 -0.21  0.05 -0.17  0.07 -0.1   0.03  0.15]\n",
            " [ 0.19 -0.03 -0.01 -0.03 -0.11  0.04  0.01  0.06]\n",
            " [-0.31  0.15  1.75 -0.17 -0.06  0.13 -1.93 -0.17]\n",
            " [-0.16  0.04 -1.26  0.1   0.49 -0.03 -1.52 -0.01]]\n",
            "\n",
            "[[ 1.18 -1.16 -0.   -0.01 -1.16  1.2  -0.01  0.01]\n",
            " [-1.16  1.17 -0.   -0.01  1.17 -1.16 -0.01 -0.01]\n",
            " [ 0.34 -0.33 -0.01 -0.01 -0.35  0.37  0.01  0.01]\n",
            " [-0.32  0.34 -0.01 -0.01  0.36 -0.35 -0.   -0.  ]]\n",
            "\n",
            "[[ 0.6  -0.72  0.61 -0.72  0.62 -0.74  0.6  -0.72]\n",
            " [-0.63  0.75 -0.61  0.75 -0.62  0.73 -0.62  0.72]\n",
            " [ 0.64 -0.73  0.62 -0.74  0.62 -0.73  0.61 -0.73]\n",
            " [-0.62  0.74 -0.62  0.73 -0.64  0.73 -0.64  0.74]]\n",
            "\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "[[ 0. -0. -0.  0.  0. -0.  0. -0.]\n",
            " [ 0.  0. -0. -0. -0. -0.  0.  0.]\n",
            " [-0. -0. -0. -0.  0.  0. -0.  0.]\n",
            " [-0. -0.  0.  0.  0. -0.  0. -0.]]\n",
            "\n",
            "[[-0.03 -0.02 -0.01  0.01  0.04  0.01  0.01 -0.  ]\n",
            " [-0.03 -0.02  0.04 -0.02  0.02  0.03  0.04  0.01]\n",
            " [-0.02  0.06  0.02  0.04 -0.   -0.01  0.02 -0.01]\n",
            " [ 0.01 -0.01 -0.01  0.02  0.    0.03 -0.   -0.02]]\n",
            "\n",
            "[[ 1.07 -1.1  -1.11  1.15  0.   -0.04 -0.    0.04]\n",
            " [-0.91  0.97  1.04 -1.09  0.03 -0.02 -0.   -0.01]\n",
            " [ 1.09 -1.1  -1.17  1.12  0.01 -0.01  0.    0.04]\n",
            " [-0.96  0.95  1.04 -1.14  0.06 -0.02 -0.   -0.02]]\n",
            "\n",
            "[[-0.03 -0.03 -0.   -0.02  0.01 -0.    0.02  0.03]\n",
            " [ 0.94  0.94  0.95  0.93 -0.73 -0.72 -0.7  -0.72]\n",
            " [ 0.03  0.01 -0.   -0.    0.01 -0.01  0.   -0.01]\n",
            " [-0.92 -0.92 -0.92 -0.91  0.76  0.74  0.75  0.73]]\n",
            "\n",
            "[[ 0.02  1.44 -0.03  0.13  0.03 -1.43 -0.06 -0.06]\n",
            " [-0.13 -1.39 -0.05  0.06  0.1   1.42  0.06  0.02]\n",
            " [ 0.05 -1.38  0.   -0.11 -0.1   1.42 -0.02  0.07]\n",
            " [-0.03  1.53 -0.02 -0.01  0.08 -1.48  0.02  0.08]]\n",
            "\n",
            "[[-0.01 -0.02  0.02 -0.    0.13 -1.25 -0.11  1.33]\n",
            " [-0.01  0.05  0.03  0.    0.13  1.68 -0.06 -1.66]\n",
            " [ 0.07 -0.01 -0.07 -0.01 -0.17  1.28  0.16 -1.3 ]\n",
            " [-0.03  0.04  0.05  0.06 -0.03 -1.63  0.06  1.68]]\n",
            "\n",
            "[[-0.17 -0.2  -0.18 -0.17  0.15  0.14  0.13  0.15]\n",
            " [ 0.17  0.17  0.16  0.19 -0.13 -0.13 -0.16 -0.13]\n",
            " [-1.05 -1.03 -1.04 -1.05  1.    0.99  1.04  1.04]\n",
            " [ 1.05  1.06  1.06  1.02 -1.03 -1.03 -1.01 -1.01]]\n",
            "\n",
            "[[-0.  0.  0. -0. -0.  0. -0.  0.]\n",
            " [ 0. -0. -0.  0.  0. -0. -0.  0.]\n",
            " [-0. -0. -0.  0. -0.  0. -0.  0.]\n",
            " [-0. -0. -0.  0. -0.  0. -0.  0.]]\n",
            "\n",
            "[[-0.11  0.09  0.12  0.02  0.18  0.11 -0.08  0.15]\n",
            " [ 0.04 -0.75  0.02 -1.    0.12 -0.75 -0.07  1.47]\n",
            " [ 0.05  0.17 -0.1   0.02  0.   -0.17 -0.08  0.12]\n",
            " [ 0.13  0.62  0.07 -0.02  0.13 -0.44 -0.05 -0.57]]\n",
            "\n",
            "[[-0.05  0.04 -0.05  0.03  1.12 -1.11  1.21 -1.18]\n",
            " [-0.06  0.04 -0.02 -0.01 -1.07  1.04 -1.11  1.16]\n",
            " [-0.04 -0.03 -0.02 -0.02 -1.12  1.17 -1.23  1.2 ]\n",
            " [-0.02  0.01  0.03 -0.04  1.12 -1.1   1.18 -1.12]]\n",
            "\n",
            "[[ 0.    0.02 -0.19 -0.07 -0.07 -0.15  0.83  0.98]\n",
            " [-0.05 -0.1  -0.02 -0.04 -0.07 -0.12 -0.86 -1.03]\n",
            " [-0.01 -0.06  0.07 -0.04 -0.05  0.04 -1.03 -1.22]\n",
            " [ 0.03  0.06  0.01 -0.06 -0.05 -0.    0.86  0.76]]\n",
            "\n",
            "[[-0.53  0.01  0.05  0.05  0.01  0.    0.   -0.02]\n",
            " [ 0.52 -0.02 -0.01 -0.04  0.    0.02  0.04  0.02]\n",
            " [-0.54  0.07  0.    0.01  0.01  0.    0.02 -0.  ]\n",
            " [ 0.52 -0.05 -0.   -0.    0.03 -0.03 -0.03  0.03]]\n",
            "\n",
            "[[-0.37 -0.46 -0.32 -0.49 -0.4  -0.37 -0.33 -0.39]\n",
            " [-0.51 -0.31 -0.38 -0.34 -0.35 -0.48 -0.42 -0.21]\n",
            " [-0.38 -0.17 -0.12 -0.5  -0.29 -0.31 -0.36 -0.09]\n",
            " [-0.26 -0.22 -0.32 -0.22 -0.18 -0.24 -0.27  0.14]]\n",
            "\n",
            "[[ 0.6  -0.62 -0.24  0.56 -0.34  0.45  0.34 -0.18]\n",
            " [-0.4   0.71  0.58 -0.69  0.51 -0.59 -0.42  0.18]\n",
            " [-0.19  0.29  0.43 -0.61  0.29 -0.4  -0.54  0.26]\n",
            " [ 0.24 -0.26 -0.93  0.22 -0.65  0.15  0.81 -1.58]]\n",
            "\n",
            "[[ 0.09 -0.29  0.74 -0.28  0.05 -0.09  0.83 -0.58]\n",
            " [-0.1  -0.11 -0.97  0.14 -0.16  0.02 -0.94  0.25]\n",
            " [-0.1   0.04 -0.33 -0.02 -0.22 -0.09 -0.33 -0.01]\n",
            " [ 0.19 -0.19  0.17  0.07  0.03  0.01  0.2  -0.23]]\n",
            "\n",
            "[[-0.91  0.04 -0.06  0.35 -0.07  0.39 -0.01 -1.52]\n",
            " [ 0.14 -0.04  0.18 -0.79  0.24 -0.8  -1.48  2.66]\n",
            " [-0.16  0.59  0.2  -1.74  0.1  -1.67 -1.22  2.98]\n",
            " [ 0.26 -1.25 -1.35  2.49 -1.43  2.41  2.94 -6.86]]\n",
            "\n",
            "[[ 0.08  0.    0.03 -0.   -0.01 -0.03  0.01  0.06]\n",
            " [ 0.    0.01  0.03  0.01 -0.03 -0.    0.01  0.08]\n",
            " [-0.01  0.13 -1.93  1.92  0.06 -0.01  1.98 -1.91]\n",
            " [ 0.06  0.01  2.31 -2.28 -0.02  0.05 -2.21  2.2 ]]\n",
            "\n",
            "[[-0.85  0.83 -0.01  0.01 -0.85  0.82 -0.03 -0.01]\n",
            " [ 0.88 -0.86 -0.01  0.01  0.87 -0.87 -0.04 -0.03]\n",
            " [ 1.   -0.98  0.01 -0.01  0.98 -0.99 -0.   -0.01]\n",
            " [-0.98  0.96 -0.01  0.01 -0.97  0.97 -0.03 -0.01]]\n",
            "\n",
            "[[-0.02 -0.02 -0.01  0.    1.34  1.35 -0.03 -0.03]\n",
            " [-0.02  0.01  0.03  0.02 -1.76 -1.76  0.03  0.01]\n",
            " [-0.    0.03  0.    0.02 -1.33 -1.3   0.03  0.04]\n",
            " [-0.01 -0.02 -0.02  0.    1.75  1.75  0.03  0.02]]\n",
            "\n",
            "[[ 0.04  0.03 -0.02  0.02  0.02 -0.01  0.02 -0.  ]\n",
            " [ 0.02 -0.05 -1.59  1.62  0.05  0.03  2.11 -2.1 ]\n",
            " [ 0.    0.03  0.03 -0.04 -0.01 -0.03 -0.01  0.07]\n",
            " [-0.01  0.    1.64 -1.62 -0.04  0.03 -2.15  2.11]]\n",
            "\n",
            "[[ 0.  0.  0.  0. -0. -0. -0. -0.]\n",
            " [ 0. -0.  0.  0. -0. -0.  0.  0.]\n",
            " [ 0.  0.  0. -0. -0.  0. -0.  0.]\n",
            " [ 0. -0. -0.  0. -0. -0. -0. -0.]]\n",
            "\n",
            "[[-0.04 -0.02  1.16  1.14 -0.04 -0.04  1.15  1.14]\n",
            " [ 0.07  0.06 -1.11 -1.12  0.06  0.03 -1.16 -1.14]\n",
            " [ 0.02  0.01 -0.86 -0.82  0.01 -0.   -0.86 -0.84]\n",
            " [-0.03 -0.03  0.86  0.81 -0.01 -0.04  0.85  0.86]]\n",
            "\n",
            "[[ 0.   -0.   -1.73  1.73  0.01 -0.02 -0.18  0.12]\n",
            " [ 0.03 -0.01  1.73 -1.73  0.01 -0.    0.2  -0.16]\n",
            " [ 0.01  0.01  1.74 -1.73 -0.01 -0.02  0.15 -0.18]\n",
            " [-0.    0.02 -1.77  1.74  0.02 -0.   -0.19  0.15]]\n",
            "\n",
            "[[-0.16 -0.06 -0.02  0.04  0.16 -0.05  0.06  0.09]\n",
            " [-0.19 -0.05 -0.    0.05  0.16  0.05  0.12  0.02]\n",
            " [ 0.15  0.05 -0.04  0.08 -0.25 -0.09 -0.07 -0.04]\n",
            " [ 0.17  0.04  0.    0.05 -0.29 -0.1  -0.09 -0.11]]\n",
            "\n",
            "[[ 0.06 -0.95 -0.58  2.62  0.05  0.19  0.21 -0.89]\n",
            " [ 0.27 -0.18 -0.18 -1.34 -0.39  0.39  0.29 -0.29]\n",
            " [-0.14  0.06  0.18 -0.7  -0.05 -0.03  0.24 -0.11]\n",
            " [-0.05  0.28  0.24 -0.01 -0.03  0.05 -0.04  0.1 ]]\n",
            "\n",
            "[[-0.04  0.2  -0.17 -0.11 -0.08 -0.17  0.03  0.08]\n",
            " [ 0.13 -1.75 -0.09  1.69 -0.2   1.81 -0.   -1.94]\n",
            " [-0.04 -0.13  0.05  0.05  0.08 -0.02 -0.16 -0.03]\n",
            " [-0.13  1.86 -0.08 -1.9  -0.09 -1.81  0.02 -2.24]]\n",
            "\n",
            "[[-0.14 -0.11  0.01  0.09  0.34  0.06  0.12  0.02]\n",
            " [-0.16 -0.06  0.3  -0.13  0.15  0.22  0.36  0.09]\n",
            " [-0.12  0.44  0.18  0.32 -0.   -0.07  0.19 -0.01]\n",
            " [ 0.14 -0.04 -0.03  0.22  0.04  0.26  0.03 -0.08]]\n",
            "\n",
            "[[ 0.08 -0.13 -0.04  0.06  0.26  0.   -0.09  0.13]\n",
            " [-0.21  0.03  0.36 -0.15 -0.06  0.05  0.13 -0.05]\n",
            " [-0.27  0.28  0.13  0.07 -0.04 -0.16  0.27 -0.15]\n",
            " [ 0.3  -0.29 -0.28  0.22 -0.02  0.32 -0.13  0.06]]\n",
            "\n",
            "[[ 0.03  0.1  -0.06 -0.54 -0.01 -0.09 -0.08 -0.47]\n",
            " [ 0.01 -0.02  0.07 -0.65 -0.07 -0.03  0.03 -0.38]\n",
            " [-0.08  0.08  0.07 -0.14  0.01  0.05  0.15  0.07]\n",
            " [-0.12 -0.01  0.02 -0.28 -0.1   0.11  0.02 -0.05]]\n",
            "\n",
            "[[-0.21  0.17 -0.07  0.16  0.41 -0.15 -0.2   0.37]\n",
            " [-0.04 -0.1   0.41  0.07 -0.08  0.32  0.4  -0.58]\n",
            " [-0.19  0.52  0.44 -0.23  0.25 -0.28  0.05  0.1 ]\n",
            " [ 0.48 -0.51 -0.5   0.52 -0.44  0.71  0.25 -0.23]]\n",
            "\n",
            "[[-0.98  0.57  0.95 -0.58 -0.97  0.59  0.96 -0.55]\n",
            " [ 0.97 -0.59 -0.99  0.56  0.97 -0.58 -0.98  0.57]\n",
            " [ 0.03 -0.    0.01  0.   -0.    0.02  0.01  0.02]\n",
            " [ 0.    0.01  0.    0.   -0.01  0.01 -0.01 -0.  ]]\n",
            "\n",
            "[[ 0.08  0.05  0.04  0.12  0.   -0.03 -0.02 -0.01]\n",
            " [-0.08 -0.03 -0.01 -0.   -0.02  0.06  0.04  0.04]\n",
            " [ 0.03 -1.68  0.01  1.85 -0.06  1.73 -0.02 -1.81]\n",
            " [-0.05  1.75 -0.02 -1.82  0.09 -1.72  0.05  1.84]]\n",
            "\n",
            "[[ 0.57 -0.57 -0.58  0.63 -0.63  0.6   0.63 -0.64]\n",
            " [ 0.03  0.02 -0.01 -0.05  0.03  0.04 -0.05 -0.07]\n",
            " [-0.63  0.65  0.63 -0.62  0.61 -0.63 -0.63  0.62]\n",
            " [ 0.06  0.04 -0.03 -0.07  0.02 -0.   -0.08 -0.09]]\n",
            "\n",
            "[[-0.05 -0.13 -0.14  0.4   0.27 -0.17  0.03 -0.27]\n",
            " [-0.16 -0.17  0.12  0.4  -0.3   0.24  0.09 -0.19]\n",
            " [-0.05  0.22  0.08  0.8  -0.14 -0.1   0.04 -0.18]\n",
            " [ 0.14  0.12  0.36  1.    0.04  0.2  -0.26 -0.76]]\n",
            "\n",
            "[[ 0.16 -0.8  -0.08  0.55 -0.13  0.41 -0.27 -0.51]\n",
            " [ 0.15  0.53 -0.6  -0.49 -0.67 -0.35  0.51 -0.31]\n",
            " [-0.24  0.81 -0.13 -1.05 -0.19 -0.93 -0.08  0.51]\n",
            " [-0.34 -0.83  0.18  0.24  0.53 -0.08 -1.15 -1.52]]\n",
            "\n",
            "[[-0.2  -0.09 -0.01  0.03  0.22  0.08  0.04 -0.  ]\n",
            " [-0.07  0.14  0.05  0.05 -0.07 -0.06  0.07  0.1 ]\n",
            " [ 1.02  1.11 -0.09  0.12 -0.97 -0.98  0.03  0.07]\n",
            " [-0.12 -0.23  0.02  0.11  0.2   0.14 -0.08 -0.02]]\n",
            "\n",
            "[[ 0.26 -0.29  1.51 -1.5  -0.29  0.28 -1.49  1.51]\n",
            " [ 0.02 -0.    0.03  0.02 -0.01  0.01  0.   -0.01]\n",
            " [ 0.28 -0.29  1.53 -1.51 -0.29  0.3  -1.51  1.55]\n",
            " [ 0.   -0.01  0.02 -0.   -0.02 -0.01 -0.    0.02]]\n",
            "\n",
            "[[ 0.01 -0.01 -0.02  0.    0.01  0.01 -0.   -0.01]\n",
            " [ 1.21 -0.81 -1.17  0.82 -1.15  0.83  1.18 -0.82]\n",
            " [ 0.01  0.    0.01  0.01  0.02  0.    0.    0.02]\n",
            " [ 1.18 -0.83 -1.18  0.83 -1.16  0.84  1.16 -0.83]]\n",
            "\n",
            "[[-0.11 -0.09 -0.    0.07  0.28  0.05  0.1   0.02]\n",
            " [-0.13 -0.05  0.24 -0.11  0.13  0.18  0.3   0.07]\n",
            " [-0.11  0.36  0.13  0.25  0.01 -0.06  0.15 -0.01]\n",
            " [ 0.1  -0.04 -0.03  0.17  0.03  0.21  0.02 -0.07]]\n",
            "\n",
            "[[-0.01  0.02  0.77  0.78  0.01 -0.02 -0.82 -0.81]\n",
            " [-0.04 -0.03 -0.79 -0.79  0.02  0.02  0.86  0.85]\n",
            " [ 0.01  0.02 -0.72 -0.71 -0.02 -0.    0.8   0.74]\n",
            " [ 0.01 -0.04  0.74  0.67  0.   -0.01 -0.78 -0.75]]\n",
            "\n",
            "[[-0.18 -0.12 -0.01  0.12  0.43  0.09  0.14  0.03]\n",
            " [-0.19 -0.05  0.37 -0.15  0.2   0.3   0.45  0.13]\n",
            " [-0.17  0.58  0.2   0.41 -0.   -0.07  0.22 -0.01]\n",
            " [ 0.19 -0.02 -0.06  0.29  0.05  0.35  0.03 -0.07]]\n",
            "\n",
            "[[ 0.03 -0.11 -0.13  0.13 -0.03 -0.03  0.02  0.07]\n",
            " [ 1.56 -1.6  -1.61  1.65  0.09 -0.   -0.15 -0.  ]\n",
            " [ 0.12 -0.09  0.02 -0.09 -0.01  0.1   0.01  0.1 ]\n",
            " [-1.43  1.42  1.61 -1.62 -0.08 -0.02  0.    0.04]]\n",
            "\n",
            "[[-0.04 -0.1  -0.15 -0.12 -0.01 -0.07 -0.15  0.03]\n",
            " [ 0.15 -0.12  0.17 -0.12  0.09  0.05  0.19  0.16]\n",
            " [-0.15  0.26  0.1  -0.2  -0.2  -0.37 -0.12  0.02]\n",
            " [-0.05 -0.15  0.16  0.09  0.03  0.03  0.21 -0.42]]\n",
            "\n",
            "[[-0.07 -1.55  0.02  1.51 -0.01 -0.01  0.04 -0.01]\n",
            " [ 0.29  1.8  -0.22 -1.84  0.03  0.03  0.    0.02]\n",
            " [ 0.07  1.57 -0.04 -1.51 -0.02 -0.01 -0.   -0.02]\n",
            " [-0.29 -1.82  0.24  1.82 -0.04 -0.01  0.    0.02]]\n",
            "\n",
            "[[ 0.97 -0.   -1.25 -0.01 -0.97 -0.01  1.27  0.04]\n",
            " [ 0.96 -0.03 -1.24  0.   -0.96 -0.    1.28  0.04]\n",
            " [-0.96  0.01  1.24  0.01  0.96  0.02 -1.27 -0.  ]\n",
            " [-0.93 -0.02  1.24 -0.01  0.97 -0.01 -1.26 -0.  ]]\n",
            "\n",
            "[[-0.07 -0.05 -0.01  0.04  0.13  0.02  0.04  0.01]\n",
            " [-0.08 -0.03  0.12 -0.06  0.06  0.09  0.14  0.03]\n",
            " [-0.06  0.18  0.06  0.13 -0.   -0.03  0.07 -0.01]\n",
            " [ 0.04 -0.02 -0.02  0.08  0.01  0.1   0.   -0.04]]\n",
            "\n",
            "[[-0.04 -0.03 -0.01  0.02  0.07  0.01  0.02  0.  ]\n",
            " [-0.05 -0.02  0.06 -0.04  0.03  0.05  0.08  0.02]\n",
            " [-0.03  0.1   0.03  0.07 -0.   -0.02  0.04 -0.01]\n",
            " [ 0.01 -0.02 -0.01  0.04  0.    0.05 -0.   -0.03]]\n",
            "\n",
            "[[-0.03 -0.1  -0.15  0.06 -0.24  0.22  0.05 -0.49]\n",
            " [ 0.08  0.12  0.23  1.55  0.01 -0.47 -0.2   1.29]\n",
            " [ 0.08 -0.07 -0.06  0.24  0.13 -0.21  0.01 -0.01]\n",
            " [-0.14  0.23 -0.08 -2.76 -0.16  0.15  0.14  2.12]]\n",
            "\n",
            "[[-0.02  0.01  0.02 -0.01  0.01 -0.    0.   -0.02]\n",
            " [-0.12  0.13  0.13 -0.12 -0.12  0.14  0.11 -0.12]\n",
            " [-0.   -0.    0.01  0.01  0.01  0.   -0.01  0.01]\n",
            " [-1.26  1.25  1.26 -1.26 -1.26  1.25  1.26 -1.24]]\n",
            "\n",
            "[[-0.1  -0.02 -0.01  0.1   0.11 -0.08 -0.05 -0.03]\n",
            " [ 0.03 -0.07 -0.08 -0.03  2.03 -2.09 -2.04  2.03]\n",
            " [ 0.04  0.01  0.03  0.04 -0.01  0.03  0.01 -0.03]\n",
            " [-0.02 -0.08  0.03 -0.06 -1.96  1.96  1.93 -2.03]]\n",
            "\n",
            "[[ 0.32 -0.36  0.05  0.65 -0.08  0.06 -0.12 -0.36]\n",
            " [-0.12 -0.18 -0.09 -0.29 -0.12  0.13  0.05  0.39]\n",
            " [-0.26  0.65  0.33 -2.34  0.11 -0.11 -0.02  1.74]\n",
            " [-0.06 -0.07  0.15  2.01  0.05  0.12 -0.48  0.75]]\n",
            "\n",
            "[[ 0.02  0.03 -0.02  0.02 -0.01  0.01 -0.06 -0.03]\n",
            " [ 0.01  0.    0.   -0.02  0.05  0.06  0.06  0.05]\n",
            " [ 0.02  0.01 -0.01  0.02 -1.4  -1.39  1.11  1.07]\n",
            " [ 0.02  0.02 -0.01 -0.    1.44  1.44 -1.12 -1.09]]\n",
            "\n",
            "[[ 0.16 -0.18 -0.07  0.12 -0.08  0.08 -0.12 -0.07]\n",
            " [-0.14 -0.04  0.36 -0.03  0.01 -0.1  -0.07 -0.04]\n",
            " [-0.11  0.06  0.35 -0.19 -0.24 -0.05  0.36 -0.29]\n",
            " [ 0.19 -0.08 -2.27  1.34 -0.2   0.08  1.74  1.26]]\n",
            "\n",
            "[[ 0.46 -0.35  0.17 -0.02  0.02 -0.38 -1.02  0.86]\n",
            " [-1.13  1.06  0.47 -0.07  0.33 -0.49  0.21 -0.43]\n",
            " [ 0.3  -0.02  0.   -0.53  0.18 -0.25 -0.   -0.06]\n",
            " [ 0.24 -0.28 -0.14  0.08  0.03 -0.19  0.03 -0.32]]\n",
            "\n",
            "[[-0.29  0.71 -0.33 -0.45  0.65 -1.19 -0.23  0.33]\n",
            " [-0.06 -0.75  0.61 -0.6  -0.76  1.03 -0.92  0.05]\n",
            " [ 0.16 -0.77 -0.16  0.05 -0.57  0.6  -0.26 -0.28]\n",
            " [-0.09  0.2  -0.84  0.47 -0.04 -0.66  0.85 -0.85]]\n",
            "\n",
            "[[-0.64  0.71 -0.64  0.69 -0.64  0.68 -0.65  0.69]\n",
            " [-0.64  0.69 -0.64  0.68 -0.64  0.7  -0.63  0.72]\n",
            " [ 0.65 -0.68  0.63 -0.7   0.66 -0.69  0.65 -0.69]\n",
            " [ 0.63 -0.69  0.61 -0.72  0.63 -0.69  0.63 -0.69]]\n",
            "\n",
            "[[ 0.18 -0.15 -0.56  0.23  0.17 -0.06  0.23 -0.13]\n",
            " [-0.24  0.27  0.4   0.2  -0.31 -0.17 -0.06 -0.18]\n",
            " [-0.14  0.13  0.47  0.07 -0.21 -0.14 -0.09  0.07]\n",
            " [-0.87 -0.32 -0.05  0.21  1.12 -0.15 -0.24 -0.31]]\n",
            "\n",
            "[[-0.3  -0.03 -0.26 -0.03  0.08  0.01  0.13  0.  ]\n",
            " [-0.02  0.1   0.2  -0.05 -0.17 -0.02 -0.06 -0.09]\n",
            " [ 1.24 -0.05  1.21 -0.14 -0.58 -0.12  0.21 -0.12]\n",
            " [ 1.85  0.01 -1.86  0.    0.05 -0.13  0.14  0.09]]\n",
            "\n",
            "[[-0.03  0.01 -0.01 -0.01 -0.02  0.   -0.02 -0.02]\n",
            " [-0.01  0.    0.01 -0.02  0.01 -0.02 -0.01 -0.02]\n",
            " [-0.83 -0.8   0.85  0.87  1.12  1.09 -1.09 -1.12]\n",
            " [-0.83 -0.82  0.83  0.84  1.11  1.1  -1.1  -1.1 ]]\n",
            "\n",
            "[[ 0.02 -0.03 -0.    0.03 -0.03  1.26  0.03 -1.24]\n",
            " [-0.05  0.01 -0.02  0.01 -0.03 -1.69  0.05  1.71]\n",
            " [-0.03  0.02 -0.   -0.01 -0.08  1.26  0.03 -1.28]\n",
            " [-0.01 -0.05 -0.01  0.05 -0.03 -1.67  0.04  1.65]]\n",
            "\n",
            "[[ 0.03  1.19 -0.01 -1.22 -0.05 -1.24  0.02  1.29]\n",
            " [-0.06  0.01 -0.06  0.02  0.05  0.06  0.06  0.06]\n",
            " [ 0.07 -1.28  0.04  1.3   0.04  1.36 -0.05 -1.24]\n",
            " [-0.02 -0.08 -0.05  0.05  0.09  0.11  0.1   0.06]]\n",
            "\n",
            "[[-0.52  0.06  0.44 -0.83 -0.28  0.25 -0.28 -0.38]\n",
            " [-0.43  0.06 -0.29 -0.14  0.36 -1.2  -0.34  0.61]\n",
            " [ 0.59 -0.83 -1.13  0.92 -0.38 -0.24  0.15 -0.3 ]\n",
            " [-0.32  0.1  -0.2  -0.5  -0.71  0.87  0.16 -1.01]]\n",
            "\n",
            "[[ 0.02  1.52 -0.   -1.5  -0.05 -1.52  0.03  1.57]\n",
            " [ 0.03  1.54 -0.   -1.57 -0.06 -1.54  0.01  1.65]\n",
            " [ 0.   -0.22 -0.01  0.21 -0.    0.25 -0.02 -0.18]\n",
            " [ 0.02 -0.28  0.    0.24 -0.02  0.31 -0.01 -0.15]]\n",
            "\n",
            "[[ 0.34 -0.01 -0.31  0.4   0.07 -0.13  0.2  -0.44]\n",
            " [-0.36 -0.    0.65  0.07 -0.25  0.07  0.25 -0.16]\n",
            " [-0.26  0.23 -2.26  0.07 -0.    0.21  0.54 -0.2 ]\n",
            " [ 0.91 -0.08 -1.09 -0.06  0.12  0.05 -0.68  0.06]]\n",
            "\n",
            "[[ 0.02 -0.01  0.03  0.03  0.01 -0.03  0.01  0.02]\n",
            " [ 0.73 -1.19  0.75 -1.19 -0.74  1.2  -0.74  1.22]\n",
            " [ 0.02  0.02  0.01  0.02  0.   -0.02  0.01  0.02]\n",
            " [ 0.74 -1.23  0.73 -1.22 -0.79  1.21 -0.77  1.21]]\n",
            "\n",
            "[[ 0.03  0.05 -0.13  0.06 -1.78  0.82  0.38 -0.1 ]\n",
            " [-0.25 -0.31  0.01  0.22  0.58  0.25  0.14 -0.18]\n",
            " [-0.13 -0.22  0.05  0.19  0.66  0.42 -0.09 -0.23]\n",
            " [ 0.07  0.08 -0.    0.09 -0.29 -0.08 -0.22 -0.18]]\n",
            "\n",
            "[[-0.06 -0.02 -0.13  0.14  0.03 -0.13 -0.13 -0.04]\n",
            " [ 0.02 -0.03  0.09 -0.25 -0.04  0.08 -0.02 -0.09]\n",
            " [-0.01  0.05 -0.03 -0.17  0.05 -0.07  0.08 -0.15]\n",
            " [-0.04 -0.93  0.03  0.94 -0.09 -0.88 -0.28  0.77]]\n",
            "\n",
            "[[ 0.   -0.62  0.   -0.63  0.02 -0.61  0.   -0.61]\n",
            " [-0.01  0.81 -0.02  0.81 -0.03  0.84 -0.01  0.85]\n",
            " [ 0.01  0.63 -0.02  0.6   0.01  0.63  0.    0.64]\n",
            " [ 0.01 -0.86  0.01 -0.87  0.01 -0.84  0.02 -0.84]]\n",
            "\n",
            "[[ 0.97  0.98 -1.   -0.99 -0.01  0.01  0.01  0.  ]\n",
            " [-0.83 -0.84  0.84  0.84 -0.    0.01 -0.    0.01]\n",
            " [ 0.97  0.98 -0.99 -0.99 -0.01  0.    0.01  0.01]\n",
            " [-0.82 -0.84  0.83  0.83 -0.01 -0.01  0.    0.01]]\n",
            "\n",
            "[[ 0.07 -0.64  0.11  0.28 -0.51  2.38  0.21 -1.08]\n",
            " [ 0.11  0.05 -0.43  0.24 -0.05 -1.34  0.18 -0.22]\n",
            " [ 0.21  0.13 -0.13 -0.07 -0.11 -0.99  0.01 -0.32]\n",
            " [-0.22  0.2   0.25  0.2   0.24 -0.09  0.16  0.27]]\n",
            "\n",
            "[[ 0.01 -0.02 -0.03 -0.01  0.    0.01  0.02  0.01]\n",
            " [ 0.04 -0.02 -0.02 -0.04  0.02 -0.01  0.01 -0.  ]\n",
            " [ 1.12 -1.1  -1.1   1.15 -0.88  0.89  0.91 -0.91]\n",
            " [ 1.11 -1.1  -1.12  1.13 -0.88  0.93  0.91 -0.89]]\n",
            "\n",
            "[[-0.07  0.05  0.05  0.    0.07 -0.02 -0.05 -0.07]\n",
            " [-0.02  0.02 -0.02 -0.02 -0.04 -0.   -0.03  0.03]\n",
            " [-0.36  0.3   0.02  0.08  1.71 -1.73 -1.82  1.71]\n",
            " [ 0.3  -0.35  0.01 -0.1  -1.71  1.73  1.74 -1.72]]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'   Input bit leyend\\n      ____________________________________________________________\\n      |              1             |||              0            |<--b2\\n      |-------------++-------------+++------+------++------+-----|\\n      |      1      ||      0      |||      1      ||      0     |<--b1\\n______|-------------++-------------+++------+------++------+-----|\\n|b4|b5|   1  |   0  ||  1   |   0  |||   1  |   0  ||  1   |  0  |<--b0\\n|--+--+------+------++-------------+++-------------++------+-----|\\n|1 |  |-0.04 | 0.05 || 0.04 |-0.03 |||-1.16 | 1.17 || 1.15 |-1.14|\\n|--+ 1+------+------++-------------+++-------------++------+-----|\\n|0 |  |-0.09 | 0.07 || 0.07 |-0.1  ||| 1.03 |-0.99 ||-1.04 | 1.01|\\n|--+--+------+------++-------------+++-------------++------+-----|\\n|--+--+------+------++-------------+++-------------++------+-----|\\n|1 |  |-0.   | 0.04 || 0.   |-0.03 ||| 0.   | 0.03 || 0.03 |-0.01|\\n|--+ 0+------+------++-------------+++-------------++------+-----|\\n|0 |  |-0.01 |-0.   || 0.02 | 0.02 ||| 0.   |-0.01 ||-0.01 |-0.03|\\n|----------------------------------------------------------------|\\n\\nOutput\\n[[-0.04  0.05  0.04 -0.03 -1.16  1.17  1.15 -1.14]\\n [-0.09  0.07  0.07 -0.1   1.03 -0.99 -1.04  1.01]\\n [-0.    0.04  0.   -0.03  0.    0.03  0.03 -0.01]\\n [-0.01 -0.    0.02  0.02  0.   -0.01 -0.01 -0.03]]\\n\\n '"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}